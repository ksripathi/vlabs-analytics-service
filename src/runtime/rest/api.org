#+TITLE: The Analytics REST API
#+AUTHOR: VLEAD
#+DATE: [2016-07-26 Tue]
#+SETUPFILE: ../../org-templates/level-2.org
#+TAGS: boilerplate(b)
#+EXCLUDE_TAGS: boilerplate
#+OPTIONS: ^:nil

* Introduction 
  This document illustrates building of the Analytics REST API.


* Analytics REST
  

** Get total Analytics Count
   + Total Analytics = Usage(stats.vlabs.ac.in) + Usage(vlabs-analytics.vlabs.ac.in)


#+NAME: get_total_usage
#+BEGIN_SRC python
@api.route('/api/totalusage')
def get_total_usage():
        try:
                res = requests.get(elk_count_url)
                elk_response = json.loads(res.content)

		req = requests.get(stats_server_url)
		stats_response = json.loads(req.content)

		total_analytics = {}
		total_analytics["description"] = "Total analytics = Usage(stats.vlabs.ac.in/analytics/) + Usage(Elasticsearch Server)"
		total_analytics["total_usage"] = elk_response["count"] + stats_response["usage"]
		return json.dumps(total_analytics)

        except:
                return "Error in communication"



#+END_SRC 


** Get Elasticsearch Analytics Count 
   + Route/API to fetch analytics from Elasticsearch Server.
   + API makes a get request to Elasticsearch and gets the total
     number of analytics record holded.
   + A call is made as shown using curl command
     #+BEGIN_SRC command
     curl http://analytics-api.vlabs.ac.in/elkusage
     #+END_SRC
   + Sample response is as shown
     #+BEGIN_SRC example_response
     {'count': 7827, '_shards': {'successful': 5, 'failed': 0, 'total': 5}}
     #+END_SRC

#+NAME: get_elkusage
#+BEGIN_SRC python
@api.route('/api/elkusage')
def get_elkusage():
        try:
                res = requests.get(elk_count_url)
                elk_response = ast.literal_eval(res.text)
                return json.dumps(elk_response)
        except:
                return "Error in communication"
#+END_SRC 


** Fetch analytics 
   + Route/API to fetch analytics from Open edX.  OpenedX POSTs data
     to analytics server API. Data POSTed is in the url.  Analytics
     server further converts that data into JSON and sends POST it to
     Elasticsearch database.
   + IP address of the Client making the request is evaluated by
     Analytics server.
   + Location of the Client is idenfied using an available opensource API 
     http://freegeoip.net/json/ 
   + Following sample analytics is captured in JSON format -
     #+BEGIN_SRC command
     {
    "DATE_OF_EXPERIMENT": "30-8-2016",
    "LAB_NAME": "PopulationEcologyII",
    "EXPERIMENT_NAME": "OptimalforagingSitAndWaitPredators",
    "TIME_OF_EXPERIMENT": "19:49",
    "COURSE_ID": "blockv1UniversityYPS01Anytime",
    "IP_ADDRESS": "196.12.53.130"
    "Location" : "Telengana"
    }
     #+END_SRC
  
#+NAME: get_analytics
#+BEGIN_SRC python

@api.route('/<analytics>',methods= ['GET','POST'])
def fetch_analytics(analytics):
        data = request.data
        fetch_data = analytics
        data_list = fetch_data.split(",") 
        data_dict = {}
        today = str(datetime.date.today())
        data_dict["STUDENT_ID"] = data_list[0]
        data_dict["LAB_ID"] = data_list[1]
        data_dict["LAB_NAME"] = data_list[2]
        #data_dict["EXPERIMENT_NAME"] = data_list[3] + "-" + data_list[2]
        #data_dict["EXPERIMENT_ID"] = data_list[4]
        data_dict["EXPERIMENT_ID"] = data_list[3]
        data_dict["EXPERIMENT_NAME"] = data_list[4]
        data_dict["DATE_OF_EXPERIMENT"] = today
        data_dict["TIME_OF_EXPERIMENT"] = time.strftime("%H:%M")
        data_dict["IP_ADDRESS"] = request.environ.get('HTTP_X_REAL_IP',request.remote_addr)
   
        res = requests.get("http://freegeoip.net/json/" + data_dict["IP_ADDRESS"])
        data = res.text
        ip_dir = ast.literal_eval(data)
        data_dict["REGION"] = ip_dir["region_name"]
        
        json_data = json.dumps(data_dict)
	res = requests.post(elk_url, data=json_data, headers=headers)   
   
        return "".format(analytics) 
   
 #+END_SRC

   
   
* Infra                                                         :boilerplate:
** sources
*** Imports 
#+name: imports_for_sources
#+BEGIN_SRC python
# -*- coding: utf-8 -*-
import os
import json
import time
import datetime
import os
from runtime.config.flask_app_config import *
from flask import send_from_directory, current_app
from flask import request, Blueprint
from elasticsearch import Elasticsearch
import requests
import ast
api = Blueprint('APIs', __name__)

#+end_src


* Tangle                                                        :boilerplate:

** sources
#+BEGIN_SRC python :tangle api.py :eval no :noweb yes
<<imports_for_sources>>
<<get_analytics>>
<<get_elkusage>>
<<get_total_usage>>
#+END_SRC



